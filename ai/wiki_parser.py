"""
Module 17: Quick Wiki
RÃ©cupÃ©ration rapide de rÃ©sumÃ©s depuis WikipÃ©dia
"""

import requests
import re
from bs4 import BeautifulSoup
from typing import Optional, Dict
import urllib.parse

class WikiParser:
    def __init__(self, lang: str = "fr"):
        """
        Initialise le parser WikipÃ©dia
        
        Args:
            lang: Langue (fr, en, es, etc.)
        """
        self.lang = lang
        self.base_url = f"https://{lang}.wikipedia.org"
        self.headers = {
            'User-Agent': 'ZodiacAI/1.0 (https://github.com/zodiac-ai)'
        }
    
    def get_summary(self, query: str, sentences: int = 3) -> Optional[Dict]:
        """
        RÃ©cupÃ¨re un rÃ©sumÃ© WikipÃ©dia
        
        Args:
            query: Terme Ã  rechercher
            sentences: Nombre de phrases dans le rÃ©sumÃ©
        
        Returns:
            Dictionnaire avec les informations ou None
        """
        try:
            # 1. Rechercher la page
            search_url = f"{self.base_url}/w/api.php"
            params = {
                'action': 'query',
                'format': 'json',
                'list': 'search',
                'srsearch': query,
                'utf8': 1
            }
            
            response = requests.get(search_url, params=params, 
                                  headers=self.headers, timeout=10)
            data = response.json()
            
            if not data.get('query', {}).get('search'):
                return None
            
            # Prendre le premier rÃ©sultat
            first_result = data['query']['search'][0]
            page_title = first_result['title']
            
            # 2. RÃ©cupÃ©rer le contenu
            content_url = f"{self.base_url}/w/api.php"
            params = {
                'action': 'query',
                'format': 'json',
                'titles': page_title,
                'prop': 'extracts|info',
                'exsentences': sentences,
                'exintro': 1,
                'explaintext': 1,
                'inprop': 'url'
            }
            
            response = requests.get(content_url, params=params,
                                  headers=self.headers, timeout=10)
            data = response.json()
            
            pages = data.get('query', {}).get('pages', {})
            if not pages:
                return None
            
            page_id = list(pages.keys())[0]
            page_data = pages[page_id]
            
            if 'missing' in page_data:
                return None
            
            # Extraire le rÃ©sumÃ©
            extract = page_data.get('extract', '')
            if not extract:
                return None
            
            # Nettoyer le texte
            extract = self.clean_text(extract)
            
            # Formater la rÃ©ponse
            result = {
                'title': page_data.get('title', ''),
                'summary': extract,
                'url': page_data.get('fullurl', ''),
                'pageid': page_id,
                'length': len(extract),
                'sentences': sentences
            }
            
            return result
            
        except Exception as e:
            print(f"âœ— Erreur WikipÃ©dia: {e}")
            return None
    
    def clean_text(self, text: str) -> str:
        """
        Nettoie le texte des balises et caractÃ¨res spÃ©ciaux
        
        Args:
            text: Texte Ã  nettoyer
        
        Returns:
            Texte nettoyÃ©
        """
        # Supprimer les rÃ©fÃ©rences [1], [2], etc.
        text = re.sub(r'\[\d+\]', '', text)
        
        # Supprimer les sauts de ligne multiples
        text = re.sub(r'\n\s*\n', '\n\n', text)
        
        # Supprimer les espaces multiples
        text = re.sub(r'\s+', ' ', text)
        
        # Nettoyer le dÃ©but (supprimer "Pour les articles homonymes", etc.)
        unwanted_patterns = [
            r'Pour les articles homonymes.*?\n',
            r'Pour l\'article homonyme.*?\n',
            r'Pour les autres significations.*?\n',
            r'\(homonymie\).*?\n'
        ]
        
        for pattern in unwanted_patterns:
            text = re.sub(pattern, '', text, flags=re.IGNORECASE)
        
        return text.strip()
    
    def search_multiple(self, queries: list, sentences: int = 2) -> Dict:
        """
        Recherche plusieurs termes
        
        Args:
            queries: Liste des termes Ã  rechercher
            sentences: Nombre de phrases par rÃ©sumÃ©
        
        Returns:
            Dictionnaire des rÃ©sultats
        """
        results = {}
        
        for query in queries:
            summary = self.get_summary(query, sentences)
            if summary:
                results[query] = summary
            else:
                results[query] = {"error": "Non trouvÃ©"}
        
        return results
    
    def get_random_article(self) -> Optional[Dict]:
        """
        RÃ©cupÃ¨re un article alÃ©atoire
        
        Returns:
            Article alÃ©atoire ou None
        """
        try:
            url = f"{self.base_url}/w/api.php"
            params = {
                'action': 'query',
                'format': 'json',
                'list': 'random',
                'rnnamespace': 0,  # Articles principaux seulement
                'rnlimit': 1
            }
            
            response = requests.get(url, params=params, 
                                  headers=self.headers, timeout=10)
            data = response.json()
            
            random_article = data['query']['random'][0]
            title = random_article['title']
            
            # RÃ©cupÃ©rer le rÃ©sumÃ©
            return self.get_summary(title, sentences=2)
            
        except Exception as e:
            print(f"âœ— Erreur article alÃ©atoire: {e}")
            return None
    
    def format_summary(self, data: Dict) -> str:
        """
        Formate le rÃ©sumÃ© pour l'affichage
        
        Args:
            data: DonnÃ©es du rÃ©sumÃ©
        
        Returns:
            ChaÃ®ne formatÃ©e
        """
        if not data or 'error' in data:
            return "âŒ Aucune information trouvÃ©e sur WikipÃ©dia."
        
        formatted = f"ğŸ“š **{data['title']}**\n\n"
        formatted += f"{data['summary']}\n\n"
        formatted += f"ğŸ”— Source: {data['url']}\n"
        formatted += f"ğŸ“ Longueur: {data['length']} caractÃ¨res"
        
        return formatted

# Test du module
if __name__ == "__main__":
    wiki = WikiParser(lang="fr")
    
    # Test de rÃ©sumÃ©
    print("ğŸ” Test Wikipedia Parser\n")
    
    # Recherche simple
    query = "Intelligence artificielle"
    result = wiki.get_summary(query, sentences=4)
    
    if result:
        print(wiki.format_summary(result))
    else:
        print(f"âœ— Aucun rÃ©sultat pour '{query}'")
    
    # Test article alÃ©atoire
    print("\nğŸ² Article alÃ©atoire:")
    random_article = wiki.get_random_article()
    if random_article:
        print(f"  Titre: {random_article['title']}")
        print(f"  RÃ©sumÃ©: {random_article['summary'][:100]}...")